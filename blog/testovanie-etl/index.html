<!doctype html><html class="dark light" lang=en><head><meta charset=UTF-8><meta content="IE=edge" http-equiv=X-UA-Compatible><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content=https://monikajassova.github.io name=base><title>
            
                Testovanie ETL
            
        </title><meta content="Testovanie ETL" property=og:title><meta content="Zopár bodov k testovaniu ETL procesov v big data." property=og:description><meta content="Zopár bodov k testovaniu ETL procesov v big data." name=description><link href=https://monikajassova.github.io/icons/favicon.ico rel=icon type=image/png><link href=/icons/favicon-32x32.png rel=icon sizes=32x32 type=image/png><link href=/icons/favicon-16x16.png rel=icon sizes=16x16 type=image/png><link crossorigin href=https://cdn.jsdelivr.net rel=preconnect><link href=https://cdn.jsdelivr.net/npm/jetbrains-mono@1.0.6/css/jetbrains-mono.min.css rel=stylesheet><link href=https://cdn.jsdelivr.net/npm/@fontsource/space-grotesk@4.5.8/index.min.css rel=stylesheet><script async data-goatcounter=https://miti.goatcounter.com/count src=https://monikajassova.github.io/js/count.js></script><noscript><img src="https://miti.goatcounter.com//count?p=/blog/testovanie-etl/&t=Testovanie ETL"></noscript><script defer src=https://monikajassova.github.io/js/codeblock.js></script><script defer src=https://monikajassova.github.io/js/toc.js></script><link title="
    Monikin ITinerár
" href=https://monikajassova.github.io/atom.xml rel=alternate type=application/atom+xml><link title="
    Monikin ITinerár
" href=https://monikajassova.github.io/rss.xml rel=alternate type=application/rss+xml><link href=https://monikajassova.github.io/theme/light.css rel=stylesheet><link href=https://monikajassova.github.io/theme/dark.css id=darkModeStyle rel=stylesheet><script src=https://monikajassova.github.io/js/themetoggle.js></script><script>setTheme(getSavedTheme());</script><link href=https://monikajassova.github.io/main.css media=screen rel=stylesheet><link href=https://monikajassova.github.io/custom.css rel=stylesheet><script src="https://monikajassova.github.io/js/searchElasticlunr.min.js?h=3626c0ef99daa745b31e" defer></script><body><div class=left-content></div><div class=content><nav><div class=left-nav><a href=https://monikajassova.github.io>Monikin ITinerár</a><div class=socials><a rel="me noopener" class=social href=https://linkedin.com/in/monika-jassova/ target=_blank> <img alt=linkedin src=https://monikajassova.github.io/icons/social/linkedin.svg> </a><a rel="me noopener" class=social href=https://github.com/MonikaJassova/ target=_blank> <img alt=github src=https://monikajassova.github.io/icons/social/github.svg> </a></div></div><div class=right-nav><a href=https://monikajassova.github.io/blog style=margin-right:.5em>/blog</a><a href=https://monikajassova.github.io/projects style=margin-right:.5em>/projekty</a><a href=https://monikajassova.github.io/tags style=margin-right:.5em>/tagy</a><a href=https://monikajassova.github.io/about style=margin-right:.5em>/o mne</a><button title="$SHORTCUT to open search" class=search-button id=search-button><img alt=Search class=search-icon src=https://monikajassova.github.io/icons/search.svg></button><div class="search-modal js" aria-labelledby=modalTitle id=searchModal role=dialog><div id=modal-content><h1 class=page-header id=modalTitle>Vyhľadávanie</h1><div id=searchBar><input aria-controls=results-container aria-expanded=false autocomplete=off id=searchInput placeholder=Hľadať... role=combobox spellcheck=false><button title="Clear Search" class=clear-button id=clear-search><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="m256-200-56-56 224-224-224-224 56-56 224 224 224-224 56 56-224 224 224 224-56 56-224-224-224 224Z"/></svg></button></div><div id=results-container><div id=results-info><span id=zero_results style=display:none>Žiadne výsledky</span><span id=one_result style=display:none>1 výsledok</span><span id=many_results style=display:none>$NUMBER výsledkov</span></div><div id=results role=listbox></div></div></div></div><a onclick="toggleTheme(); event.preventDefault();" href=# id=dark-mode-toggle> <img alt=Light id=sun-icon src=https://monikajassova.github.io/icons/sun.svg> <img alt=Dark id=moon-icon src=https://monikajassova.github.io/icons/moon.svg style=filter:invert()> <img alt=Auto id=auto-icon src=https://monikajassova.github.io/icons/auto.svg style=filter:invert()> </a><script>updateItemToggleTheme()</script></div></nav><div data-selector="main article p" class=visible-element-observer-root><main><article><div class=title><div class=page-header>Testovanie ETL</div><div class=meta>Publikované <time>07.06.2022</time><span class=tags-label> ::</span><span class=tags> <a class=post-tag href=https://monikajassova.github.io/tags/it/>IT</a> <a class=post-tag href=https://monikajassova.github.io/tags/big-data/>big data</a> <a class=post-tag href=https://monikajassova.github.io/tags/testovanie/>testovanie</a> </span></div></div><section class=body><p><em>Cieľom tohto článku je zosumarizovať postupy, ktoré som implementovala pri testovaní ETL procesov a s ktorými som sa stretla v rámci big data</em><h1 id=uvod-do-big-data-a-etl><a aria-label="Anchor link for: uvod-do-big-data-a-etl" class=zola-anchor href=#uvod-do-big-data-a-etl>Úvod do big data a ETL</a></h1><p>Veľké dáta (ďalej big data) sú charakterizované troma V:<ol><li>volume - veľký objem dát,<li>velocity - rýchlosť s akou sú produkované (gigabajty nových dát denne),<li>variety - dáta prichádzajú z rôznych zdrojov a v rôznej forme.</ol><p>Sú to také veľké súbory dát, že ich nie je možné uchovávať, spravovať a spracovávať bežne používanými softvérovými prostriedkami v rozumnom čase.<br> Úlohou dátových inžinierov je spracovanie big data a ich príprava do požadovanej podoby pre ďalších používateľov dát - spravidla dátových analytikov, dátových vedcov.<p>Jeden z procesov, ktorým sa to deje, sa nazýva <mark>ETL</mark> (extract-transform-load).<br> V prvej fáze ETL sa dáta extrahujú zo zdrojov - sťahujú sa z FTP serverov, cloudových úložísk, dotazujú sa cez REST API a pod. Surové dáta môžu mať rôznu štruktúru - tabuľky v relačných databázach, záznamy v NoSQL databázach, súbory formátu CSV, XML, JSON atď.<br> Počas fázy transformácie sa dáta upravujú podľa požadovaných pravidiel, filtrujú, očisťujú, spájajú s inými dátami, prevádzajú sa nad nimi agregácie alebo iné výpočty. Tieto medzivýsledky sa držia v oblasti staged.<br> V záverečnej fáze sa finálne dáta publikujú na dohodnutom mieste, spravidla v dátovom sklade (data warehouse - DWH), kde ich priamo alebo cez connectory vedia používatelia dotazovať, pracovať s nimi, využiť ako podklad pre analytické a BI (business intelligence) nástroje.</p><img alt="ETL proces" aspect-ratio="686 / 686" decoding=async loading=lazy src=https://monikajassova.github.io/processed_images/etl.1f7fc3bfc7095f9b.avif><p>Novším prístupom je <mark>ELT</mark> (extract-load-transform) proces, pri ktorom sa surové dáta nahrajú na cieľový systém a transformácie sa vykonávajú až tam, napr. s pomocou nástroja <a rel="noopener external" class=external href=https://www.getdbt.com target=_blank>dbt</a>.<p>ETL procesy môžu prebiehať:<ul><li>dávkovo - <mark>batch processing</mark>, kedy sú spúšťané periodicky, riadené orchestrátorom<li>ako <mark>streaming</mark>, kedy sú dáta spracúvané v reálnom čase ako prichádzajú do systému</ul><p>Na našom projekte sme uplatňovali batch processing a ako orchestrátor pre definovanie workflowow a plánovanie ich behov sme používali <a rel="noopener external" class=external href=https://oozie.apache.org target=_blank>Oozie</a> a neskôr aj <a rel="noopener external" class=external href=https://airflow.apache.org target=_blank>Airflow</a>. Ukážka ako taký workflow môže vyzerať (<a rel="noopener external" class=external href=https://www.aakashpydi.com/jetstream-architecture/ target=_blank>zdroj obrázka</a>):</p><img alt="Workflow v Airflow" aspect-ratio="1097 / 1097" decoding=async loading=lazy src=https://monikajassova.github.io/processed_images/airflow.70bfbe8fcfa85d73.avif><p>Na samotné spracúvanie dát sme používali Apache Spark, o ktorom som písala <a href=https://monikajassova.github.io/blog/spark/>v tomto príspevku</a>. Pre predstavu na akom HW Spark a Hadoop bežal, išlo o Oracle BDA/HDFS cluster o 12 uzloch (každý s procesorom Intel XEON), ktorý dokopy disponoval 1 TB RAM a 900 TB HDD.<p>Testovanie a zabezpečenie kvality ETL procesov bolo náplňou mojej práce v DAZN. Keď som nastúpila, big data boli pre mňa nové a netušila som, ako to budem testovať. Online zdrojov k téme testovania dát je poskromne aj teraz a keď som začínala, nachádzala som len odkazy na platené nástroje, ale máločo o konkrétnych metódach. Názvy testov v nasledujúcom texte sú interné označenia, nejde o odbornú terminológiu.<h1 id=datove-e2e-testy><a aria-label="Anchor link for: datove-e2e-testy" class=zola-anchor href=#datove-e2e-testy>Dátové E2E testy</a></h1><p>Prvým krokom pri zavedení automatizovaného testovania jednotlivých ETL procesov bolo vytvorenie niečoho ako E2E testov nad fixnými dátami. V prostredí som vytvorila osobitné priečinky, kde som si pripravila súbory s testovacími dátami po vzore reálnych. Malú vzorku, tak aby som mala kontrolu nad tým, čo v nej je a čo sa s ňou deje. Pripravila som dáta pre rôzne testovacie prípady, tzv. happy path aj okrajové prípady, či sa do výsledku dostávajú skutočne tie dáta, ktoré majú.<br> Nad týmito dátami som púšťala workflowy, ktoré ich spracovali a na konci sa výsledné dáta porovnali s očakávaným výsledkom. Automatizovaný test alebo pomocný skript na záver všetky výsledné dáta aj medzivýsledky ETL procesu zmazal a pripravil prostredie na ďalší beh celého testovacieho workflowu.<br> Ak bol ETL proces jednoduchý a napr. zabezpečoval len, aby sa v published držala najnovšia verzia záznamu, automatizované testy bežali na produkčných dátach a porovnávali vstupné dáta s výstupnými.<p>E2E testy pomohli vyriešiť záhadný bug - mala som podozrenie, že občas majú niektoré záznamy isté hodnoty dvojnásobné ako by mali byť, ale nevedeli sme kedy a prečo sa tak deje. Až keď som sa dostala k nasimulovaniu celého procesu a dát, tak som zistila, že v špecifickom prípade, keď dáta spadali do dvoch kategórií, tieto sa započítali dvakrát.<h1 id=testy-konzistentnosti><a aria-label="Anchor link for: testy-konzistentnosti" class=zola-anchor href=#testy-konzistentnosti>Testy konzistentnosti</a></h1><p>Ďalšou skupinou automatizovaných testov boli testy, ktoré zisťovali, či sú produkčné dáta konzistentné z hľadiska logiky domény. Príklad z digitálneho marketingu: počet kliknutí na reklamu musí byť menší ako počet videní a ten zas menší ako počet požiadaviek o reklamu odoslaných serveru.<p>Testy konzistentnosti sme vo veľkom využili pri implementácii produktu single customer view v grafovej databáze Neo4j. Grafová databáza je koncept umožňujúci jednoducho modelovať vzťahy reálne existujúce v doméne. Ukážka vzťahov medzi rôznymi uzlami a dopytovacieho jazyka Cypher:</p><img aspect-ratio="1313 / 1313" alt=Neo4j decoding=async loading=lazy src=https://monikajassova.github.io/processed_images/cypher.2e92ad76e5de7ef8.avif><p>Testy overovali, či skutočný stav zodpovedá navrhnutému dátovému modelu grafu - či sú správne vlastnosti uzlov a vzťahov, či nie sú vzťahy duplicitné, či sa v grafe nenachádzajú entity po TTL (time-to-live). Testy konzistentnosti nám pomohli nájsť chyby v implementácii grafu, identifikovať veci, ktoré sme doposiaľ pri implementácii neošetrili a tiež skryté zlyhania workflowov.<h1 id=monitoring><a aria-label="Anchor link for: monitoring" class=zola-anchor href=#monitoring>Monitoring</a></h1><p>Tretím pilierom, ktorý nám veľmi pomohol odhaľovať problémy a anomálie a zvýšiť dôveru vo fungovanie našich ETL procesov, bolo nastavenie monitoringu metrík týkajúcich sa dát a samotných ETL procesov. Použili sme na to <a rel="noopener external" class=external href=https://www.elastic.co/kibana target=_blank>Kibanu</a> od Elasticu (existuje veľa alternatív, napr. open-source <a rel="noopener external" class=external href=https://grafana.com target=_blank>Grafana</a>). Vytypovali sme metriky, ktoré sa opäť periodicky spúšťali ako Spark aplikácie (metriky týkajúce sa súborov na HDFS a tabuliek v Hive), Scala aplikácie (metriky týkajúce sa grafu v Neo4j a workflowov v Oozie) alebo bash skripty (metriky týkajúce sa tabuliek v BigQuery) a zaznamenávali hodnoty v logoch pre Kibanu.<p align=center><img alt="Metrika v Kibane" src=/metric.png><p>Išlo napr. o počet modifikovaných uzlov v daný deň (na obrázku vyššie); veľkosť surových dát, ktoré sa stiahli daný deň; sumy záznamov vo výsledných dátach; dĺžku trvania ETL procesu.<br> Do Kibany reportovali výsledky aj testy, ktoré kontrolovali, či sú prítomné dáta z každej hodiny dňa, či boli všetky surové dáta spracované, či všetky staged dáta boli publikované a či sa na HDFS nenachádzajú staré súbory, ktoré mali byť vymazané po uplynutí doby retencie dát. Nastavila som alerty, aby sme boli o takýchto udalostiach notifikovaní emailom.<h1 id=kvalita-dat-katalog-dat-a-spol><a aria-label="Anchor link for: kvalita-dat-katalog-dat-a-spol" class=zola-anchor href=#kvalita-dat-katalog-dat-a-spol>Kvalita dát, katalóg dát a spol.</a></h1><p>Testy boli hotové - vyžadovali len údržbu, monitoring fičal, tak som začala rešeršovať, aké vychytávky by sa ešte dali zaradiť a tým dvihnúť kvalitu našich ETL procesov na ešte vyššiu úroveň. Bohužiaľ, k skúsenostiam s nasledovnými nástrojmi z prvej ruky som sa už nedostala, keďže priority na projekte sa presunuli smerom od big data a neskôr som zmenila pôsobisko.<p>Profilovanie dát je proces skúmania zdrojových dát a porozumenia ich štruktúre, obsahu a vzájomných vzťahov s cieľom identifikovania potenciálu pre dátové projekty. Výsledky testovania, monitoringu a profilovania a ich sprievodné vizualizácie môžu pomôcť identifikovať vzory v dátach a príležitosti prepojenia datasetov, značkovania a pridania metadát s cieľom lepšie identifikovať a kategorizovať informácie v organizácii.<p>Nástroje na kvalitu dát umožňujú analýzu datasetu, validáciu dát, profilovanie dát, odhalenie nevalidných (napr. duplicitné záznamy, hodnoty v stĺpci nezodpovedajúce dátovému typu alebo rozsahu hodnôt, v akom by mali byť), chýbajúcich alebo neobvyklých dát. Nastavujú sa prahy akceptovaných parametrov pre dáta s dobrou kvalitou, oproti ktorým sa dáta testujú a pravidelne kontrolujú, či spĺňajú vopred definované pravidlá a štandardy kvality. Zámerom bolo zapojiť takéto testy do workflowu a zastaviť ďalšie spracovávanie datasetu, ak by obsahoval zlé dáta a tým zabrániť zavedeniu zlých dát do published.<br> Pre tieto účely som našla knižnicu <a rel="noopener external" class=external href=https://greatexpectations.io target=_blank>Great Expectations</a>, nemohli sme ju však použiť kvôli nekompatibilnej verzii Pythonu na našom clusteri. Great Expectations umožňuje tiež automatickú dokumentáciu dát. Až neskôr som objavila alternatívy pre Scalu ako <a rel="noopener external" class=external href=https://github.com/awslabs/deequ target=_blank>Deequ</a>, <a rel="noopener external" class=external href=https://github.com/FRosner/drunken-data-quality target=_blank>DDQ</a>, <a rel="noopener external" class=external href=https://github.com/databrickslabs/dataframe-rules-engine target=_blank>DataFrame Rules Engine</a> a <a rel="noopener external" class=external href=https://griffin.apache.org target=_blank>Apache Griffin</a>. <a rel="noopener external" class=external href=https://github.com/sodadata/soda-sql target=_blank>Soda SQL</a> operuje nad dátami prístupnými SQL, podporuje Amazon Redshift, Apache Hive a Spark, Snowflake a niekoľko DB a pravidlá sa definujú v YAML formáte. Umožňuje aj používanie vlastných metrík.<p>Zaujímavo sa javili aj nástroje na vytvorenie katalógu dát <a rel="noopener external" class=external href=https://www.amundsen.io target=_blank>Amundsen</a> a na pôvod dát a vizualizáciu procesov <a rel="noopener external" class=external href=https://absaoss.github.io/spline target=_blank>Apache Spline</a>. Katalóg dát slúži ako organizovaný inventár dát pre dátových inžinierov a používateľov dát, kde môžu na jednom mieste vyhľadávať dáta vhodné pre svoje potreby.<p>Pomocou môžu byť aj riešenia založené na strojovom učení (ML), ktoré by sa natrénovali na historických dátach a odhaľovali anomálie v novopríchodzích.<h1 id=zaver><a aria-label="Anchor link for: zaver" class=zola-anchor href=#zaver>Záver</a></h1><p>ETL procesy a ich testovanie sú menšinová oblasť IT, ale majú svoje čaro. Postupom času zistíte, kde všade môže nastať problém. Niekoľko takých tipov na čo si dať pozor:<ul><li>prehodenie hodnôt medzi dvoma stĺpcami rovnakého dátového typu<li>náhle zastavenie dodávania dát od tretej strany<li>náhla zmena schémy surových dát<li>hodiny dát naviac a menej v dňoch prechodu na letný čas a späť<li>uistite sa, že sťahujete naozaj všetky surové dáta z ich zdroja<li>uistite sa, že nahrávate naozaj všetky spracované dáta na cieľový systém<li>pravidelne zálohujte dáta, môže sa stať, že workflow vymaže/pokazí časť dát<li>dobré je aj pravidelne sledovať historické dáta v cieľovom systéme, môže sa stať, že workflow vymaže časť dát, nahrá dáta viackrát alebo prepíše inú partíciu ako má a takto to môžete zistiť<li>pozor na upgrady používaných nástrojov. Spark 2.4 zmenil ako sa ukladajú prázdne reťazce z CSV (null/prázdny reťazec), čo malo vplyv na spájanie datasetov na dotknutom stĺpci<li>ak beh workflowu prechádza cez polnoc (alebo inú pre Vás relevantnú časovú hranicu), uistite sa, že všetky kroky workflowu pracujú s tými batchmi dát, s ktorými majú</ul></section></article></main></div><div class=giscus></div><script async crossorigin issue-term=pathname repo=MonikaJassova/monikajassova.github.io src=https://utteranc.es/client.js theme=github-dark></script><footer class=footer>© Monika Jaššová, 2022 - 2026</footer></div><div class=right-content><div class=toc><div class=heading>Obsah</div><ul class=toc-list><li class=parent><a href=https://monikajassova.github.io/blog/testovanie-etl/#uvod-do-big-data-a-etl>Úvod do big data a ETL</a><li class=parent><a href=https://monikajassova.github.io/blog/testovanie-etl/#datove-e2e-testy>Dátové E2E testy</a><li class=parent><a href=https://monikajassova.github.io/blog/testovanie-etl/#testy-konzistentnosti>Testy konzistentnosti</a><li class=parent><a href=https://monikajassova.github.io/blog/testovanie-etl/#monitoring>Monitoring</a><li class=parent><a href=https://monikajassova.github.io/blog/testovanie-etl/#kvalita-dat-katalog-dat-a-spol>Kvalita dát, katalóg dát a spol.</a><li class=parent><a href=https://monikajassova.github.io/blog/testovanie-etl/#zaver>Záver</a></ul></div></div>