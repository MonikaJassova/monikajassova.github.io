<!doctype html><html class="dark light" lang=en><head><meta charset=UTF-8><meta content="IE=edge" http-equiv=X-UA-Compatible><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content=https://monikajassova.github.io name=base><title>
            
                Apache Spark
            
        </title><meta content="Apache Spark" property=og:title><meta content="Prehľad Apache Spark" property=og:description><meta content="Prehľad Apache Spark" name=description><link href=https://monikajassova.github.io/icons/favicon.ico rel=icon type=image/png><link href=/icons/favicon-32x32.png rel=icon sizes=32x32 type=image/png><link href=/icons/favicon-16x16.png rel=icon sizes=16x16 type=image/png><link crossorigin href=https://cdn.jsdelivr.net rel=preconnect><link href=https://cdn.jsdelivr.net/npm/jetbrains-mono@1.0.6/css/jetbrains-mono.min.css rel=stylesheet><link href=https://cdn.jsdelivr.net/npm/@fontsource/space-grotesk@4.5.8/index.min.css rel=stylesheet><script async data-goatcounter=https://miti.goatcounter.com/count src=https://monikajassova.github.io/js/count.js></script><noscript><img src="https://miti.goatcounter.com//count?p=/blog/spark/&t=Apache Spark"></noscript><script defer src=https://monikajassova.github.io/js/codeblock.js></script><script defer src=https://monikajassova.github.io/js/toc.js></script><link title="
    Monikin ITinerár
" href=https://monikajassova.github.io/atom.xml rel=alternate type=application/atom+xml><link title="
    Monikin ITinerár
" href=https://monikajassova.github.io/rss.xml rel=alternate type=application/rss+xml><link href=https://monikajassova.github.io/theme/light.css rel=stylesheet><link href=https://monikajassova.github.io/theme/dark.css id=darkModeStyle rel=stylesheet><script src=https://monikajassova.github.io/js/themetoggle.js></script><script>setTheme(getSavedTheme());</script><link href=https://monikajassova.github.io/main.css media=screen rel=stylesheet><link href=https://monikajassova.github.io/custom.css rel=stylesheet><script src="https://monikajassova.github.io/js/searchElasticlunr.min.js?h=3626c0ef99daa745b31e" defer></script><body><div class=left-content></div><div class=content><nav><div class=left-nav><a href=https://monikajassova.github.io>Monikin ITinerár</a><div class=socials><a rel="me noopener" class=social href=https://linkedin.com/in/monika-jassova/ target=_blank> <img alt=linkedin src=https://monikajassova.github.io/icons/social/linkedin.svg> </a><a rel="me noopener" class=social href=https://github.com/MonikaJassova/ target=_blank> <img alt=github src=https://monikajassova.github.io/icons/social/github.svg> </a></div></div><div class=right-nav><a href=https://monikajassova.github.io/blog style=margin-right:.5em>/blog</a><a href=https://monikajassova.github.io/projects style=margin-right:.5em>/projekty</a><a href=https://monikajassova.github.io/tags style=margin-right:.5em>/tagy</a><a href=https://monikajassova.github.io/about style=margin-right:.5em>/o mne</a><button title="$SHORTCUT to open search" class=search-button id=search-button><img alt=Search class=search-icon src=https://monikajassova.github.io/icons/search.svg></button><div class="search-modal js" aria-labelledby=modalTitle id=searchModal role=dialog><div id=modal-content><h1 class=page-header id=modalTitle>Vyhľadávanie</h1><div id=searchBar><input aria-controls=results-container aria-expanded=false autocomplete=off id=searchInput placeholder=Hľadať... role=combobox spellcheck=false><button title="Clear Search" class=clear-button id=clear-search><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="m256-200-56-56 224-224-224-224 56-56 224 224 224-224 56 56-224 224 224 224-56 56-224-224-224 224Z"/></svg></button></div><div id=results-container><div id=results-info><span id=zero_results style=display:none>Žiadne výsledky</span><span id=one_result style=display:none>1 výsledok</span><span id=many_results style=display:none>$NUMBER výsledkov</span></div><div id=results role=listbox></div></div></div></div><a onclick="toggleTheme(); event.preventDefault();" href=# id=dark-mode-toggle> <img alt=Light id=sun-icon src=https://monikajassova.github.io/icons/sun.svg> <img alt=Dark id=moon-icon src=https://monikajassova.github.io/icons/moon.svg style=filter:invert()> <img alt=Auto id=auto-icon src=https://monikajassova.github.io/icons/auto.svg style=filter:invert()> </a><script>updateItemToggleTheme()</script></div></nav><div data-selector="main article p" class=visible-element-observer-root><main><article><div class=title><div class=page-header>Apache Spark</div><div class=meta>Publikované <time>21.05.2022</time><span class=tags-label> ::</span><span class=tags> <a class=post-tag href=https://monikajassova.github.io/tags/it/>IT</a> <a class=post-tag href=https://monikajassova.github.io/tags/big-data/>big data</a> </span></div></div><section class=body><p><em>Zbežný prehľad fungovania Apache Spark</em><p><a rel="noopener external" class=external href=https://spark.apache.org target=_blank>Apache Spark</a> je jedným z najpoužívanejších nástrojov pre analýzu dát vo veľkej škále (big data), rieši situáciu, keď sú dáta také veľké, že ich uloženie a spracovanie nedokáže jeden počítač. Zvláda dávkové (batch) spracovávanie dát, spracovávanie dát v reálnom čase (streaming), interaktívne dotazovanie, výpočty a operácie s grafom a strojové učenie (machine learning).<br> Ide o open-source framework na spracovanie dát, ktorý dokáže rýchlo vykonávať procesovacie úlohy nad veľmi veľkými množinami dát a tiež dokáže tieto úlohy distribuovať medzi viacero počítačov, ktoré ich paralelne a nezávisle od seba spracúvajú. Pre svoje fungovanie vyžaduje manažér clustera počítačov (napr. Hadoop YARN - Yet Another Resource Negotiator) a distribuovaný systém súborov (napr. HDFS - Hadoop Distributed File System).<p>Obrázok znázorňuje 4 knižnice pre rôzne účely a programovacie jazyky, ktoré podporuje základné API:</p><img alt="Spark Ecosystem" aspect-ratio="701 / 701" decoding=async loading=lazy src=https://monikajassova.github.io/processed_images/SparkEcosystem.fee7e630793de3d3.avif><p>Spark je napísaný v programovacom jazyku <a rel="noopener external" class=external href=https://www.scala-lang.org target=_blank>Scala</a>, prvá verzia vyšla v roku 2010 (od 2014 pod hlavičkou firmy Apache) a najnovšia verzia je 3.2.1 z januára 2022.<br> Spočiatku sa Spark využíval na vlastnom "železe" - firmy vlastnili a starali sa o svoje Hadoop clustere, v dnešnej dobe cloudu sa už poskytuje ako manažovaná alebo serverless služba, menovite <a rel="noopener external" class=external href=https://aws.amazon.com/emr target=_blank>Amazon EMR</a>, <a rel="noopener external" class=external href=https://azure.microsoft.com/en-us/services/databricks target=_blank>Azure Databricks</a> alebo <a rel="noopener external" class=external href=https://cloud.google.com/solutions/spark target=_blank>Spark on Google Cloud</a>, takže používateľom odpadá starosť o manažovanie clustera.<h1 id=spark-core><a aria-label="Anchor link for: spark-core" class=zola-anchor href=#spark-core>Spark Core</a></h1><p>Je základným kameňom Sparku a ide o rozhranie pre programovanie aplikácií sústredené okolo abstrakcie nazývanej RDD. Najprv však priblížim 2 procesy, ktoré naštartuje Spark cluster po spustení Spark aplikácie:<ul><li><mark>driver</mark> je hlavný, riadiaci proces zodpovedný za vytvorenie Spark contextu, preklad kódu Spark aplikácie na logický plán DAG a následne na výpočtové jednotky, úlohy, ktoré sú distribuované medzi pracovné uzly (worker nodes). Taktiež koordinuje rozvrhnutie úloh a orchestráciu na každom exekútore.<li><mark>exekútory</mark> bežia na pracovných uzloch clustra a sú zodpovedné za výkon im pridelených výpočtových úloh, vrátenie výsledkov driveru a tiež poskytnutie úložiska pre RDD. Medzivýsledky jednotlivých operácií sa držia v distribuovanej pamäti, neukladajú sa na disk (len ak sa nevojdú do RAM), preto sú veľmi rýchle.</ul><p>Práve pre sprostredkovanie medzi týmito procesmi je potrebná nejaká forma cluster manažéra - okrem spomínaného YARNu sa novšie používa <a rel="noopener external" class=external href=https://spark.apache.org/docs/latest/running-on-kubernetes.html target=_blank>Kubernetes</a>.<h2 id=spark-rdd><a aria-label="Anchor link for: spark-rdd" class=zola-anchor href=#spark-rdd>Spark RDD</a></h2><p>Resilient Distributed Dataset (RDD) je abstrakcia reprezentujúca nemennú kolekciu objektov, ktorá môže byť rozdistribuovaná medzi výpočtový cluster. Operácie nad RDD sa tiež dajú rozdeliť medzi uzly clustera a sú vykonávané v paralelnom dávkovom procese, čo vedie k rýchlemu a škálovateľnému procesovaniu.<p>Spark RDD API uvádza niekoľko transformácií a akcií pre manipuláciu s RDD:<ul><li>Transformácie RDD vracajú vždy nový RDD a umožňujú vytvoriť závislosti medzi RDD. Každý RDD v reťazi závislostí má funkciu na výpočet svojich dát a smerník na svoj rodičovský RDD. Transformácia RDD je krok v programe hovoriaci Sparku ako získať dáta a čo s nimi robiť.<li>Akcie nad RDD vracajú samotný výsledok, hodnotu (napr. reduce, count, collect). Výsledok môže byť uložený na disk, zapísaný do databázy alebo vypísaný do konzoly. RDD sú vyhodnocované odložene (lenivo - lazy evaluation), vyhodnotenie sa nezačne, kým nie je zavolaná nejaká akcia.</ul><p>Resilient - odolný alebo schopný obnoviť činnosť - znamená, že ak v niektorom kroku procesu operácia/exekútor spadne, nie je to žiaden problém a potrebný RDD sa obnoví zo vstupných dát a danou reťazou závislostí a transformácií. Beh Spark aplikácie môže pokračovať, celkové spracovanie dát nie je ohrozené a je teda odolné voči zlyhaniam.<p>Prvotný RDD sa vytvorí paralelným načítaním dát do zvláštnych partícií na jednotlivých pracovných uzloch. Takto má každý uzol inú podmnožinu dát - logickú časť veľkej distribuovanej množiny dát. Exekútory obdržia na spracovanie jednu alebo viac partícií. Exekútor vykonáva v danom čase vždy len jednu úlohu pre danú partíciu. Rozhodovanie o počte partícií je hľadanie kompromisu: ak rozdelíme RDD na veľa menších partícií, rozvrhovanie úloh môže zabrať viac času ako samotný výpočet a na druhej strane málo veľkých partícií môže znamenať, že nedôjde k vyťaženiu všetkých pracovných uzlov a nevyužijú sa tak výhody paralelizmu.<p>RDD môžu byť vytvorené dvomi spôsobmi:<ol><li>odkazovaním sa na súbor dát v externom úložnom systéme, ako je zdieľaný súborový systém, HDFS, HBase, jednoduchý textový súbor, SQL databáza, NoSQL sklad (ako Cassandra a MongoDB), bucket na úložisku Amazon S3 a veľa iných,<li>paralelizovaním existujúcej kolekcie v programe drivera - aplikovaním transformácií na existujúcich RDD. Okrem tradičnej map and reduce funkcionality má Spark tiež vstavanú podporu pre spájanie data setov, filtrovanie a agregácie.</ol><h2 id=dag><a aria-label="Anchor link for: dag" class=zola-anchor href=#dag>DAG</a></h2><p>Druhou hlavnou abstrakciou v Sparku je DAG (directed acyclic graph). Spark definuje úlohy, ktoré môžu byť paralelne vypočítané nad partíciami dát v clusteri. Zostrojí logický tok operácií, ktorý je reprezentovaný ako riadený acyklický graf, kde uzly predstavujú RDD partície a hrany transformácie dát.<br> Logický plán DAGu sa podľa povahy transformácií skonvertuje na <mark>fyzický exekučný plán</mark> pozostávajúci z etáp (stages). Úlohy v každej etape sa zbalia spolu a pošlú exekútorom. Príklad takého plánu:</p><img alt="Príklad plánu" aspect-ratio="691 / 691" decoding=async loading=lazy src=https://monikajassova.github.io/processed_images/plan.8f5d05d8714abae8.avif><p>Na etapu 1 nadväzuje etapa 2, etapa 3 je nezávislá na nich a môže bežať paralelne, v etape 4 sa spoja RDD z etáp 2 a 3.<h1 id=spark-sql><a aria-label="Anchor link for: spark-sql" class=zola-anchor href=#spark-sql>Spark SQL</a></h1><p>Spark SQL priniesol dátovú abstrakciu nazývanú DataFrame, táto poskytuje podporu pre štruktúrované a semištruktúrované dáta (JSON). DataFrame je distribuovaná kolekcia objektov typu Row organizovaná do pomenovaných stĺpcov, koncepčne zodpovedá tabuľke v relačnej databáze.<br> DataFramy sú takisto ako RDD nemenné.<br> Spark SQL poskytuje štandardné rozhranie pre čítanie dát z a zapisovanie do rôznych dátových úložísk vrátane JSON a CSV súborov, Apache Hive, JDBC, Apache Avro, Apache Parquet, existujú aj connectory pre MongoDB atď. Spark SQL umožňuje dotazovať dáta v rámci Spark aplikácií s použitím DataFrame API alebo SQL dotazov (slúži ako distribuovaný SQL query engine).<p>Ukážka DataFrame API vs SQL:<pre class=giallo style=color:#cdd6f4;background-color:#1e1e2e><code data-lang=scala><span class=giallo-l><span>spark.read.table(</span><span style=color:#a6e3a1>"published_mediabi.clicks"</span><span>)</span></span>
<span class=giallo-l><span>  .where(col(</span><span style=color:#a6e3a1>"dt"</span><span>)</span><span style=color:#94e2d5> ===</span><span style=color:#a6e3a1> "2020-12-08"</span><span>)</span></span>
<span class=giallo-l><span>  .agg(sum(</span><span style=color:#a6e3a1>"clicks"</span><span>))</span></span>
<span class=giallo-l></span>
<span class=giallo-l><span>spark.sql(</span><span style=color:#a6e3a1>"SELECT SUM(clicks) FROM published_mediabi.clicks WHERE dt = '2020-12-08'"</span><span>)</span></span></code></pre><h1 id=spark-shell><a aria-label="Anchor link for: spark-shell" class=zola-anchor href=#spark-shell>Spark Shell</a></h1><p>Na rýchle ad-hoc analýzy, prototypovanie a testovanie sa používa Spark shell. Ak si chcete Spark prakticky vyskúšať na lokálnom počítači, je to možné práve v tejto konzole (stačí mať nainštalovanú Javu), po <a rel="noopener external" class=external href=https://spark.apache.org/downloads.html target=_blank>stiahnutí</a> ju spustíte z rozbaleného adresára príkazom<pre class=giallo style=color:#cdd6f4;background-color:#1e1e2e><code data-lang=shellscript><span class=giallo-l><span style=color:#89b4fa;font-style:italic>./bin/spark-shell</span></span></code></pre><ul><li>v rámci konzoly funguje automatické dokončovanie pomocou <code>TAB</code><li>pomoc zobrazíme <code>:help</code><li>históriu príkazov <code>:history</code><li>do paste módu pre vloženie viacriadkového kusu kódu sa dostaneme <code>:paste</code> (a von z neho <code>CTRL</code>+<code>D</code>)<li>Scala skript môžeme načítať <code>:load &lt;cesta k súboru></code><li>prácu v konzole ukončíme <code>:quit</code></ul><p>Spark shell pri spustení vytvorí:<ol><li>premennú <mark>sc</mark> pre prístup k SparkContextu (vstupný bod Spark Core funkcionality)<li>premennú <mark>spark</mark> pre prístup k SparkSession (vstupný bod Spark SQL funkcionality)</ol><p>Príklady načítania dát:<pre class=giallo style=color:#cdd6f4;background-color:#1e1e2e><code data-lang=scala><span class=giallo-l><span>spark.read.parquet(</span><span style=color:#a6e3a1>"/data/staged/ott/mediabi/googledfp/NetworkImpressions/dt=20201209"</span><span>)</span></span>
<span class=giallo-l><span>spark.read.option(</span><span style=color:#a6e3a1>"header"</span><span>, </span><span style=color:#f38ba8>true</span><span>).csv(</span><span style=color:#a6e3a1>"/data/staged/media/scv/bluekai_insights_categories/dt=20201209"</span><span>)</span></span>
<span class=giallo-l><span>spark.read.table(</span><span style=color:#a6e3a1>"staged_mediabi.dfp_etl_status"</span><span>)</span></span></code></pre><p>Spustenie príkladov pribalených k inštalácii Sparku a celú dokumentáciu nájdete na <a rel="noopener external" class=external href=https://spark.apache.org/docs/latest/#running-the-examples-and-shell target=_blank>https://spark.apache.org/docs/latest/#running-the-examples-and-shell</a></section></article></main></div><div class=giscus></div><script async crossorigin issue-term=pathname repo=MonikaJassova/monikajassova.github.io src=https://utteranc.es/client.js theme=github-dark></script><footer class=footer>© Monika Jaššová, 2022 - 2026</footer></div><div class=right-content><div class=toc><div class=heading>Obsah</div><ul class=toc-list><li class=parent><a href=https://monikajassova.github.io/blog/spark/#spark-core>Spark Core</a> <ul><li><a href=https://monikajassova.github.io/blog/spark/#spark-rdd>Spark RDD</a><li><a href=https://monikajassova.github.io/blog/spark/#dag>DAG</a></ul><li class=parent><a href=https://monikajassova.github.io/blog/spark/#spark-sql>Spark SQL</a><li class=parent><a href=https://monikajassova.github.io/blog/spark/#spark-shell>Spark Shell</a></ul></div></div>