---
title: Testovanie ETL
description: ZopÃ¡r bodov k testovaniu ETL procesov v big data.
date: 2022-06-08
tags:
  - IT
  - big data
  - testovanie
layout: layouts/post.njk
image: /img/etl.png
---

*CieÄ¾om tohto ÄlÃ¡nku je zosumarizovaÅ¥ postupy, ktorÃ© som implementovala pri testovanÃ­ ETL procesov a s ktorÃ½mi som sa stretla v rÃ¡mci big data*

## Ãšvod do big data a ETL
VeÄ¾kÃ© dÃ¡ta (Äalej big data) sÃº charakterizovanÃ© troma V:
1. volume - veÄ¾kÃ½ objem dÃ¡t, rÃ¡dovo v GB a viac,
2. velocity - rÃ½chlosÅ¥ s akou sÃº produkovanÃ©, GB novÃ½ch dÃ¡t denne,
3. variety - dÃ¡ta prichÃ¡dzajÃº z rÃ´znych zdrojov a v rÃ´znej forme.

SÃº to takÃ© veÄ¾kÃ© sÃºbory dÃ¡t, Å¾e ich nie je moÅ¾nÃ© zachytÃ¡vaÅ¥, spravovaÅ¥ a spracovÃ¡vaÅ¥ beÅ¾ne pouÅ¾Ã­vanÃ½mi softvÃ©rovÃ½mi prostriedkami v rozumnom Äase.
Ãšlohou dÃ¡tovÃ½ch inÅ¾inierov je spracovanie big data a ich prÃ­prava do poÅ¾adovanej podoby pre ÄalÅ¡Ã­ch pouÅ¾Ã­vateÄ¾ov dÃ¡t - spravidla dÃ¡tovÃ½ch analytikov, dÃ¡tovÃ½ch vedcov.

Jeden z procesov, ktorÃ½m sa to deje, sa nazÃ½va <mark>ETL</mark> (extract-transform-load).
V prvej fÃ¡ze ETL sa dÃ¡ta extrahujÃº zo zdrojov - sÅ¥ahujÃº sa z FTP serverov, cloudovÃ½ch ÃºloÅ¾Ã­sk, dotazujÃº sa cez REST API a pod. SurovÃ© dÃ¡ta mÃ´Å¾u maÅ¥ rÃ´znu Å¡truktÃºru - tabuÄ¾ky v relaÄnÃ½ch databÃ¡zach, zÃ¡znamy v NoSQL databÃ¡zach, sÃºbory formÃ¡tu CSV, XML, JSON atÄ.
PoÄas fÃ¡zy transformÃ¡cie sa dÃ¡ta upravujÃº podÄ¾a poÅ¾adovanÃ½ch pravidiel, filtrujÃº, oÄisÅ¥ujÃº, spÃ¡jajÃº s inÃ½mi dÃ¡tami, prevÃ¡dzajÃº sa nad nimi agregÃ¡cie alebo inÃ© vÃ½poÄty. Tieto medzivÃ½sledky sa drÅ¾ia v oblasti staged.
V zÃ¡vereÄnej fÃ¡ze sa spracovanÃ© dÃ¡ta publikujÃº na dohodnutom mieste, spravidla v dÃ¡tovom sklade (data warehouse - DWH), kde ich priamo alebo cez connectory vedia pouÅ¾Ã­vatelia dotazovaÅ¥, pracovaÅ¥ s nimi.

![ETL proces](/img/etl.png)

ETL procesy mÃ´Å¾u prebiehaÅ¥:
 - dÃ¡vkovo - <mark>batch processing</mark>, kedy sÃº spÃºÅ¡Å¥anÃ© periodicky, riadenÃ© nejakÃ½m orchestrÃ¡torom
 - ako <mark>streaming</mark>, kedy sÃº dÃ¡ta spracÃºvanÃ© v podstate v reÃ¡lnom Äase ako prichÃ¡dzajÃº do systÃ©mu

Na naÅ¡om projekte sme pouÅ¾Ã­vali batch processing. Pre predstavu akÃ½ HW nÃ¡Å¡ projekt vyuÅ¾Ã­val, iÅ¡lo o BDA/HDFS cluster od Oracle o 12 uzloch (kaÅ¾dÃ½ s procesorom Intel XEON), ktorÃ½ dokopy disponoval 1 TB RAM a 900 TB HDD.

NovÅ¡Ã­m prÃ­stupom je <mark>ELT</mark> (extract-load-transform), pri ktorom sa transformÃ¡cie vykonÃ¡vajÃº na cieÄ¾ovom systÃ©me vtedy, keÄ sÃº potrebnÃ©, napr. s pomocou nÃ¡stroja [dbt](https://www.getdbt.com).

Testovanie a zabezpeÄenie kvality ETL procesov bolo nÃ¡plÅˆou mojej prÃ¡ce v DAZN. KeÄ som nastÃºpila, bola to pre mÅˆa Ãºplne novÃ¡ domÃ©na a netuÅ¡ila som, ako to budem testovaÅ¥. Online zdrojov k tÃ©me testovania dÃ¡t je poskromne aj teraz a keÄ som zaÄÃ­nala, nachÃ¡dzala som len odkazy na platenÃ© nÃ¡stroje na testovanie big data, ale mÃ¡loÄo o konkrÃ©tnych postupoch a metÃ³dach. NÃ¡zvy testov v nasledujÃºcom texte sÃº internÃ© oznaÄenia, nejde o odbornÃº terminolÃ³giu.

## DÃ¡tovÃ© E2E testy
PrvÃ½m krokom pri zavedenÃ­ automatizovanÃ©ho testovania jednotlivÃ½ch ETL procesov bolo vytvorenie nieÄoho ako E2E testov. Na testovacom prostredÃ­ som vytvorila osobitnÃ© prieÄinky, kde som si pripravila sÃºbory s testovacÃ­mi dÃ¡tami po vzore reÃ¡lnych. MalÃº vzorku, tak aby som mala kontrolu nad tÃ½m, Äo v nej je a Äo sa s Åˆou deje. Pripravila som dÃ¡ta pre rÃ´zne testovacie prÃ­pady, tzv. happy path aj okrajovÃ© prÃ­pady, Äi sa do vÃ½sledku dostÃ¡vajÃº skutoÄne tie dÃ¡ta, ktorÃ© majÃº.
Nad tÃ½mito dÃ¡tami som pÃºÅ¡Å¥ala reÃ¡lne produkÄnÃ© workflowy, ktorÃ© ich spracovali a na konci sa vÃ½slednÃ© dÃ¡ta porovnali s oÄakÃ¡vanÃ½m vÃ½sledkom. AutomatizovanÃ½ test alebo pomocnÃ½ skript na zÃ¡ver vÅ¡etky vÃ½slednÃ© dÃ¡ta aj medzivÃ½sledky ETL procesu zmazal a pripravil prostredie na ÄalÅ¡Ã­ beh celÃ©ho testovacieho workflowu.
Ak bol ETL proces jednoduchÃ½ a napr. zabezpeÄoval len, aby sa v published drÅ¾ala najnovÅ¡ia verzia zÃ¡znamu, automatizovanÃ© testy beÅ¾ali na produkÄnÃ½ch dÃ¡tach a porovnÃ¡vali vstupnÃ© dÃ¡ta s vÃ½stupnÃ½mi.
E2E testy pomohli odhaliÅ¥ zapeklitÃ½ bug - mala som podozrenie, Å¾e obÄas majÃº niektorÃ© zÃ¡znamy istÃ© hodnoty dvojnÃ¡sobnÃ© ako by mali byÅ¥, ale nevedeli sme kedy a preÄo sa tak deje. AÅ¾ keÄ som sa dostala k nasimulovaniu celÃ©ho procesu a dÃ¡t, tak som zistila, Å¾e v Å¡pecifickom prÃ­pade, keÄ dÃ¡ta spadali do dvoch kategÃ³riÃ­, tieto sa zapoÄÃ­tali dvakrÃ¡t.

## Testy konzistentnosti
ÄalÅ¡ou skupinou automatizovanÃ½ch testov boli testy, ktorÃ© zisÅ¥ovali, Äi sÃº produkÄnÃ© dÃ¡ta konzistentnÃ© z hÄ¾adiska logiky systÃ©mu. PrÃ­klad z digitÃ¡lneho marketingu a analytiky: poÄet kliknutÃ­ na reklamu musÃ­ byÅ¥ menÅ¡Ã­ ako poÄet videnÃ­ a ten zas menÅ¡Ã­ ako poÄet poÅ¾iadavok o reklamu odoslanÃ½ch serveru.
Testy konzistentnosti nÃ¡m pomohli pri implementÃ¡cii produktu single customer view v grafovej databÃ¡ze Neo4j. UkÃ¡Å¾ka vzÅ¥ahov medzi rÃ´znymi uzlami a dotazovacieho jazyka Cypher:

![Neo4j](/img/cypher.png)

Testy overovali, Äi skutoÄnÃ½ stav zodpovedÃ¡ navrhnutÃ©mu dÃ¡tovÃ©mu modelu grafu - Äi sÃº sprÃ¡vne atribÃºty uzlov a vzÅ¥ahov, Äi nie sÃº vzÅ¥ahy duplicitnÃ©, Äi sa v grafe nenachÃ¡dzajÃº entity po TTL (time-to-live). Testy konzistentnosti nÃ¡m pomohli nÃ¡jsÅ¥ chyby v implementÃ¡cii grafu, identifikovaÅ¥ veci, na ktorÃ© sme doposiaÄ¾ pri implementÃ¡cii nemysleli a tieÅ¾ skrytÃ© zlyhania workflowov.

## Monitoring
TretÃ­m pilierom, ktorÃ½ nÃ¡m veÄ¾mi pomohol odhaÄ¾ovaÅ¥ problÃ©my a anomÃ¡lie a zvÃ½Å¡iÅ¥ dÃ´veru vo fungovanie naÅ¡ich ETL procesov, bolo nastavenie monitoringu metrÃ­k tÃ½kajÃºcich sa dÃ¡t a samotnÃ½ch ETL procesov. PouÅ¾ili sme na to konkrÃ©tne [Kibanu](https://www.elastic.co/kibana) od Elasticu (existuje veÄ¾a alternatÃ­v, napr. open-source [Grafana](https://grafana.com)). Vytypovali sme metriky, ktorÃ© sa opÃ¤Å¥ periodicky spÃºÅ¡Å¥ali ako Spark aplikÃ¡cie (metriky tÃ½kajÃºce sa HDFS a Hive), Scala aplikÃ¡cie (metriky tÃ½kajÃºce sa Neo4j) alebo bash skripty (metriky tÃ½kajÃºce sa BigQuery) a zaznamenÃ¡vali hodnoty v logoch pre Kibanu.

<p align="center">
    <img src="/img/metric.png" alt="Metrika v Kibane"/>
</p>

IÅ¡lo napr. o poÄet modifikovanÃ½ch uzlov v danÃ½ deÅˆ na obrÃ¡zku vyÅ¡Å¡ie; veÄ¾kosÅ¥ surovÃ½ch dÃ¡t, ktorÃ© sa stiahli danÃ½ deÅˆ; sumy zÃ¡znamov vo vÃ½slednÃ½ch dÃ¡tach; trvanie ETL procesu.
Do Kibany reportovali vÃ½sledky aj testy, ktorÃ© kontrolovali, Äi sÃº prÃ­tomnÃ© dÃ¡ta z kaÅ¾dej hodiny dÅˆa, Äi boli vÅ¡etky surovÃ© dÃ¡ta spracovanÃ©, Äi vÅ¡etky staged dÃ¡ta boli publikovanÃ© a Äi sa na HDFS nenachÃ¡dzajÃº starÃ© sÃºbory, ktorÃ© mali byÅ¥ vymazanÃ© po uplynutÃ­ doby retencie dÃ¡t. Nastavila som alerty, aby sme boli o takÃ½chto udalostiach notifikovanÃ­ emailom.

## Kvalita dÃ¡t, katalÃ³g dÃ¡t a spol.
ÄalÅ¡Ã­m rieÅ¡enÃ­m, ktorÃ© som reÅ¡erÅ¡ovala, boli nÃ¡stroje na kvalitu dÃ¡t. UmoÅ¾ÅˆujÃº analÃ½zu datasetu, validÃ¡ciu dÃ¡t, profilovanie dÃ¡t, odhalenie nevalidnÃ½ch (napr. duplicitnÃ© zÃ¡znamy, hodnoty v stÄºpci nezodpovedajÃºce dÃ¡tovÃ©mu typu alebo rozsahu hodnÃ´t, v akom by mali byÅ¥), chÃ½bajÃºcich alebo neobvyklÃ½ch dÃ¡t. ZÃ¡merom bolo zapojiÅ¥ takÃ©to testy do CI/CD pipelinu a zastaviÅ¥ ÄalÅ¡ie spracovÃ¡vanie datasetu, ak by obsahoval zlÃ© dÃ¡ta a tÃ½m zabrÃ¡niÅ¥ zavedeniu zlÃ½ch dÃ¡t do published.
Pre tieto ÃºÄely som naÅ¡la kniÅ¾nicu [Great Expectations](https://greatexpectations.io), nemohli sme ju vÅ¡ak pouÅ¾iÅ¥ kvÃ´li nekompatibilnej verzii Pythonu na naÅ¡om clustri. Great Expectations umoÅ¾Åˆuje tieÅ¾ automatickÃº dokumentÃ¡ciu dÃ¡t. AÅ¾ neskÃ´r som objavila alternatÃ­vy pre Scalu ako [Deequ](https://github.com/awslabs/deequ), [DDQ](https://github.com/FRosner/drunken-data-quality), [DataFrame Rules Engine](https://github.com/databrickslabs/dataframe-rules-engine) a [Apache Griffin](https://griffin.apache.org). [Soda SQL](https://github.com/sodadata/soda-sql) operuje nad dÃ¡tami prÃ­stupnÃ½mi SQL, podporuje Amazon Redshift, Apache Hive a Spark, Snowflake a niekoÄ¾ko DB a pravidlÃ¡ sa definujÃº v YAML formÃ¡te. UmoÅ¾Åˆuje aj pouÅ¾Ã­vanie vlastnÃ½ch metrÃ­k.

Pod monitoringom dÃ¡t sa rozumie pravidelnÃ© kontrolovanie dÃ¡t, Äi spÄºÅˆajÃº vopred definovanÃ© pravidlÃ¡ a Å¡tandardy kvality. ZahÅ•Åˆa kalkulÃ¡ciu metrÃ­k, ktorÃ© nie sÃº priamo retrievable in a dataset as raw metadata, such as invalid, missing, or unexpected values. NastavujÃº sa prahy akceptovanÃ½ch parametrov pre dÃ¡ta s dobrou kvalitou, oproti ktorÃ½m sa dÃ¡ta testujÃº.

Profilovanie dÃ¡t zahÅ•Åˆa pouÅ¾Ã­vanie vÃ½sledkov testovania a monitoringu na prehodnotenie Å¡truktÃºry dÃ¡t, vzÃ¡jomnÃ½ch vzÅ¥ahov a kvality na zistenie ako najlepÅ¡ie pouÅ¾iÅ¥ dÃ¡ta pre rÃ´zne biznis ÃºÄely. SpomÃ­nanÃ© vÃ½sledky predoÅ¡lÃ½ch aktivÃ­t a ich sprievodnÃ© vizualizÃ¡cie mÃ´Å¾u pomÃ´cÅ¥ identifikovaÅ¥ vzory v dÃ¡tach a prÃ­leÅ¾itosti prepojenia datasetov, znaÄkovania a pridania metadÃ¡t s cieÄ¾om lepÅ¡ie identifikovaÅ¥ a kategorizovaÅ¥ informÃ¡cie v organizÃ¡cii.

Data observability je o vyuÅ¾itÃ­ vÃ½stupu z dÃ¡tovÃ½ch systÃ©mov â€“ metrÃ­k, logov a traces â€“ na zÃ­skanie priebeÅ¾nej viditeÄ¾nosti do celkovÃ©ho zdravia dÃ¡t s systÃ©moch. DÃ¡tovÃ© sklady a nÃ¡stroje na transformÃ¡ciu dÃ¡t produkujÃº kvantum metadÃ¡t o aktivite, ktorÃ¡ prebieha v datasete a tieto sa dajÃº pouÅ¾iÅ¥ na priebeÅ¾nÃ© check for and anticipate issues. Monitoring dÃ¡t hlÃ¡si, Å¾e â€œMÃ¡me problÃ©mâ€, nÃ¡stroje pre data observability ponÃºkajÃº detailnejÅ¡Ã­ pohÄ¾ad na operÃ¡cie v systÃ©me, jeho zdravie a vÃ½konnosÅ¥; a produkujÃº konkrÃ©tne nÃ¡hÄ¾ady ako â€œTento proces zlyhal kvÃ´li neplatnÃ©mu riadku v datasete Xâ€.

ZaujÃ­mavo sa javili aj nÃ¡stroje na vytvorenie katalÃ³gu dÃ¡t [Amundsen](https://www.amundsen.io) a na pÃ´vod dÃ¡t a vizualizÃ¡ciu procesov [Apache Spline](https://absaoss.github.io/spline). KatalÃ³g dÃ¡t slÃºÅ¾i ako organizovanÃ½ inventÃ¡r dÃ¡t pre dÃ¡tovÃ½ch inÅ¾inierov a pouÅ¾Ã­vateÄ¾ov dÃ¡t, kde mÃ´Å¾u na jednom mieste vyhÄ¾adÃ¡vaÅ¥ dÃ¡ta vhodnÃ© pre svoje potreby.

K vyuÅ¾itiu tÃ½chto nÃ¡strojov som sa uÅ¾ nedostala, keÄÅ¾e priority na projekte sa presunuli smerom od big data a neskÃ´r som zmenila pÃ´sobisko. To je z mojej anabÃ¡zy v big data vÅ¡etko ğŸ™‚
