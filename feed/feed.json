{
  "version": "https://jsonfeed.org/version/1",
  "title": "Domov",
  "home_page_url": "https://monikajassova.github.io",
  "feed_url": "https://monikajassova.github.io/feed/feed.json",
  "description": "Monikin ITinerár",
  "author": {
    "name": "Monika Jaššová",
    "url": ""
  },
  "items": [{
      "id": "https://monikajassova.github.io/posts/spark/",
      "url": "https://monikajassova.github.io/posts/spark/",
      "title": "Apache Spark",
      "content_html": "<p><em>Zbežný prehľad fungovania Apache Spark</em></p>\n<p><a href=\"https://spark.apache.org\">Apache Spark</a> je jedným z najpoužívanejších nástrojov pre analýzu dát vo veľkej škále (big data), rieši situáciu, keď sú dáta také veľké, že ich uloženie a spracovanie nedokáže jeden počítač. Zvláda dávkové (batch) spracovávanie dát, spracovávanie dát v reálnom čase (streaming), interaktívne dotazovanie, výpočty a operácie s grafom a strojové učenie (machine learning).<br>\nIde o open-source framework na spracovanie dát, ktorý dokáže rýchlo vykonávať procesovacie úlohy nad veľmi veľkými množinami dát a tiež dokáže tieto úlohy distribuovať medzi viacero počítačov, ktoré ich paralelne a nezávisle od seba spracúvajú. Pre svoje fungovanie vyžaduje manažér clustera počítačov (napr. Hadoop YARN - Yet Another Resource Negotiator) a distribuovaný systém súborov (napr. HDFS - Hadoop Distributed File System).<br>\nObrázok znázorňuje 4 knižnice pre rôzne účely a programovacie jazyky, ktoré podporuje základné API:</p>\n<p><img src=\"/img/SparkEcosystem.png\" alt=\"Spark Ecosystem\"></p>\n<p>Spark je napísaný v programovacom jazyku <a href=\"https://www.scala-lang.org\">Scala</a>, prvá verzia vyšla v roku 2010 (od 2014 pod hlavičkou firmy Apache) a najnovšia verzia je 3.2.1 z januára 2022.<br>\nSpočiatku sa Spark využíval na vlastnom &quot;železe&quot; - firmy vlastnili a starali sa o svoje Hadoop clustere, v dnešnej dobe cloudu sa už poskytuje ako manažovaná alebo serverless služba, menovite <a href=\"https://aws.amazon.com/emr\">Amazon EMR</a>, <a href=\"https://azure.microsoft.com/en-us/services/databricks\">Azure Databricks</a> alebo <a href=\"https://cloud.google.com/solutions/spark\">Spark on Google Cloud</a>, takže používateľom odpadá starosť o manažovanie clustera.</p>\n<h3 id=\"spark-core\">Spark Core <a class=\"direct-link\" href=\"#spark-core\">#</a></h3>\n<p>Je základným kameňom Sparku a ide o rozhranie pre programovanie aplikácií sústredené okolo abstrakcie nazývanej RDD.<br>\nNajprv však priblížim 2 procesy, ktoré naštartuje Spark cluster po spustení Spark aplikácie:</p>\n<ul>\n<li><mark>driver</mark> je hlavný, riadiaci proces zodpovedný za vytvorenie Spark contextu, preklad kódu Spark aplikácie na logický plán DAG a následne na výpočtové jednotky, úlohy, ktoré sú distribuované medzi pracovné uzly (worker nodes). Taktiež koordinuje rozvrhnutie úloh a orchestráciu na každom exekútore.</li>\n<li><mark>exekútory</mark> bežia na pracovných uzloch clustra a sú zodpovedné za výkon im pridelených výpočtových úloh, vrátenie výsledkov driveru a tiež poskytnutie úložiska pre RDD. Medzivýsledky jednotlivých operácií sa držia v distribuovanej pamäti, neukladajú sa na disk (len ak sa nevojdú do RAM), preto sú veľmi rýchle.</li>\n</ul>\n<p>Práve pre sprostredkovanie medzi týmito procesmi je potrebná nejaká forma cluster manažéra - okrem spomínaného YARNu sa novšie používa <a href=\"https://spark.apache.org/docs/latest/running-on-kubernetes.html\">Kubernetes</a>.</p>\n<h4 id=\"spark-rdd\">Spark RDD <a class=\"direct-link\" href=\"#spark-rdd\">#</a></h4>\n<p>Resilient Distributed Dataset (RDD) je abstrakcia reprezentujúca nemennú kolekciu objektov, ktorá môže byť rozdistribuovaná medzi výpočtový cluster. Operácie nad RDD sa tiež dajú rozdeliť medzi uzly clustera a sú vykonávané v paralelnom dávkovom procese, čo vedie k rýchlemu a škálovateľnému procesovaniu.</p>\n<p>Spark RDD API uvádza niekoľko transformácií a akcií pre manipuláciu s RDD:</p>\n<ul>\n<li>Transformácie RDD vracajú vždy nový RDD a umožňujú vytvoriť závislosti medzi RDD. Každý RDD v reťazi závislostí má funkciu na výpočet svojich dát a smerník na svoj rodičovský RDD. Transformácia RDD je krok v programe hovoriaci Sparku ako získať dáta a čo s nimi robiť.</li>\n<li>Akcie nad RDD vracajú samotný výsledok, hodnotu (napr. reduce, count, collect). Výsledok môže byť uložený na disk, zapísaný do databázy alebo vypísaný do konzoly. RDD sú vyhodnocované odložene (lenivo - lazy evaluation), vyhodnotenie sa nezačne, kým nie je zavolaná nejaká akcia.</li>\n</ul>\n<p>Resilient - odolný alebo schopný obnoviť činnosť - znamená, že ak v niektorom kroku procesu operácia/exekútor spadne, nie je to žiaden problém a potrebný RDD sa obnoví zo vstupných dát a danou reťazou závislostí a transformácií. Beh Spark aplikácie môže pokračovať, celkové spracovanie dát nie je ohrozené a je teda odolné voči zlyhaniam.</p>\n<p>Prvotný RDD sa vytvorí paralelným načítaním dát do zvláštnych partícií na jednotlivých pracovných uzloch. Takto má každý uzol inú podmnožinu dát - logickú časť veľkej distribuovanej množiny dát. Exekútory obdržia na spracovanie jednu alebo viac partícií. Exekútor vykonáva v danom čase vždy len jednu úlohu pre danú partíciu. Rozhodovanie o počte partícií je hľadanie kompromisu: ak rozdelíme RDD na veľa menších partícií, rozvrhovanie úloh môže zabrať viac času ako samotný výpočet a na druhej strane málo veľkých partícií môže znamenať, že nedôjde k vyťaženiu všetkých pracovných uzlov a nevyužijú sa tak výhody paralelizmu.</p>\n<p>RDD môžu byť vytvorené dvomi spôsobmi:</p>\n<ol>\n<li>odkazovaním sa na súbor dát v externom úložnom systéme, ako je zdieľaný súborový systém, HDFS, HBase, jednoduchý textový súbor, SQL databáza, NoSQL sklad (ako Cassandra a MongoDB), bucket na úložisku Amazon S3 a veľa iných,</li>\n<li>paralelizovaním existujúcej kolekcie v programe drivera - aplikovaním transformácií na existujúcich RDD. Okrem tradičnej map and reduce funkcionality má Spark tiež vstavanú podporu pre spájanie data setov, filtrovanie a agregácie.</li>\n</ol>\n<h4 id=\"dag\">DAG <a class=\"direct-link\" href=\"#dag\">#</a></h4>\n<p>Druhou hlavnou abstrakciou v Sparku je DAG (directed acyclic graph). Spark definuje úlohy, ktoré môžu byť paralelne vypočítané nad partíciami dát v clusteri. Zostrojí logický tok operácií, ktorý je reprezentovaný ako riadený acyklický graf, kde uzly predstavujú RDD partície a hrany transformácie dát.<br>\nLogický plán DAGu sa podľa povahy transformácií skonvertuje na <mark>fyzický exekučný plán</mark> pozostávajúci z etáp (stages). Úlohy v každej etape sa zbalia spolu a pošlú exekútorom. Príklad takého plánu:</p>\n<p><img src=\"/img/plan.png\" alt=\"Príklad plánu\"></p>\n<p>Na etapu 1 nadväzuje etapa 2, etapa 3 je nezávislá na nich a môže bežať paralelne, v etape 4 sa spoja RDD z etáp 2 a 3.</p>\n<h3 id=\"spark-sql\">Spark SQL <a class=\"direct-link\" href=\"#spark-sql\">#</a></h3>\n<p>Spark SQL priniesol dátovú abstrakciu nazývanú DataFrame, táto poskytuje podporu pre štruktúrované a semištruktúrované dáta (JSON).<br>\nDataFrame je distribuovaná kolekcia objektov typu Row organizovaná do pomenovaných stĺpcov, koncepčne zodpovedá tabuľke v relačnej databáze.<br>\nDataFramy sú takisto ako RDD nemenné.<br>\nSpark SQL poskytuje štandardné rozhranie pre čítanie dát z a zapisovanie do rôznych dátových úložísk vrátane JSON a CSV súborov, Apache Hive, JDBC, Apache Avro, Apache Parquet, existujú aj connectory pre MongoDB atď.<br>\nSpark SQL umožňuje dotazovať dáta v rámci Spark aplikácií s použitím DataFrame API alebo SQL dotazov (slúži ako distribuovaný SQL query engine).</p>\n<p>Ukážka DataFrame API vs SQL:</p>\n<pre class=\"language-scala\"><code class=\"language-scala\">spark<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">.</span>table<span class=\"token punctuation\">(</span><span class=\"token string\">\"published_mediabi.clicks\"</span><span class=\"token punctuation\">)</span><br>  <span class=\"token punctuation\">.</span>where<span class=\"token punctuation\">(</span>col<span class=\"token punctuation\">(</span><span class=\"token string\">\"dt\"</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span><span class=\"token operator\">=</span> <span class=\"token string\">\"2020-12-08\"</span><span class=\"token punctuation\">)</span><br>  <span class=\"token punctuation\">.</span>agg<span class=\"token punctuation\">(</span>sum<span class=\"token punctuation\">(</span><span class=\"token string\">\"clicks\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><br><br>spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">(</span><span class=\"token string\">\"SELECT SUM(clicks) FROM published_mediabi.clicks WHERE dt = '2020-12-08'\"</span><span class=\"token punctuation\">)</span></code></pre>\n<h3 id=\"spark-shell\">Spark Shell <a class=\"direct-link\" href=\"#spark-shell\">#</a></h3>\n<p>Na rýchle ad-hoc analýzy, prototypovanie a testovanie sa používa Spark shell.<br>\nAk si chcete Spark prakticky vyskúšať na lokálnom počítači, je to možné práve v tejto konzole (stačí mať nainštalovanú Javu), po <a href=\"https://spark.apache.org/downloads.html\">stiahnutí</a> ju spustíte z rozbaleného adresára príkazom</p>\n<pre class=\"language-bash\"><code class=\"language-bash\">./bin/spark-shell</code></pre>\n<ul>\n<li>v rámci konzoly funguje automatické dokončovanie pomocou <code>TAB</code></li>\n<li>pomoc zobrazíme <code>:help</code></li>\n<li>históriu príkazov <code>:history</code></li>\n<li>do paste módu pre vloženie viacriadkového kusu kódu sa dostaneme <code>:paste</code> (a von z neho <code>CTRL</code>+<code>D</code>)</li>\n<li>Scala skript môžeme načítať <code>:load &lt;cesta k súboru&gt;</code></li>\n<li>prácu v konzole ukončíme <code>:quit</code></li>\n</ul>\n<p>Spark shell pri spustení vytvorí:</p>\n<ol>\n<li>premennú <mark>sc</mark> pre prístup k SparkContextu (vstupný bod Spark Core funkcionality)</li>\n<li>premennú <mark>spark</mark> pre prístup k SparkSession (vstupný bod Spark SQL funkcionality)</li>\n</ol>\n<p>Príklady načítania dát:</p>\n<pre class=\"language-scala\"><code class=\"language-scala\">spark<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">.</span>parquet<span class=\"token punctuation\">(</span><span class=\"token string\">\"/data/staged/ott/mediabi/googledfp/NetworkImpressions/dt=20201209\"</span><span class=\"token punctuation\">)</span><br>spark<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">.</span>option<span class=\"token punctuation\">(</span><span class=\"token string\">\"header\"</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>csv<span class=\"token punctuation\">(</span><span class=\"token string\">\"/data/staged/media/scv/bluekai_insights_categories/dt=20201209\"</span><span class=\"token punctuation\">)</span><br>spark<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">.</span>table<span class=\"token punctuation\">(</span><span class=\"token string\">\"staged_mediabi.dfp_etl_status\"</span><span class=\"token punctuation\">)</span></code></pre>\n<p>Spustenie príkladov pribalených k inštalácii Sparku a celú dokumentáciu nájdete na <a href=\"https://spark.apache.org/docs/latest/#running-the-examples-and-shell\">https://spark.apache.org/docs/latest/#running-the-examples-and-shell</a></p>\n",
      "date_published": "2022-05-21T00:00:00-00:00"
    },{
      "id": "https://monikajassova.github.io/posts/uzitocne-zdroje/",
      "url": "https://monikajassova.github.io/posts/uzitocne-zdroje/",
      "title": "Užitočné zdroje",
      "content_html": "<p><em>Na tomto mieste nájdete zoznam rôznych užitočných odkazov, ktorý budem aktualizovať</em></p>\n<p><a href=\"https://www.freecodecamp.org\">https://www.freecodecamp.org</a> Bezplatné tutoriály rôzneho druhu vo forme článkov a videí, dajú sa nájsť aj rozsiahle do hĺbky spracované témy</p>\n<p><a href=\"https://testautomationu.applitools.com\">https://testautomationu.applitools.com</a> Bezplatné kurzy zamerané na automatizovaný testing, aj okrajové témy</p>\n<p><a href=\"https://www.baeldung.com\">https://www.baeldung.com</a> Jednohubky aj dlhšie návody hlavne z JVM sveta: Java, Spring, Scala, Kotlin a tiež Linux a počítačová veda</p>\n<p><a href=\"https://skillmea.sk\">https://skillmea.sk</a> Bývalý learn2code - taký zlatý štandard kurzov v slovenskom jazyku - od programovania cez testing a grafiku až po marketing a iné</p>\n<p><a href=\"https://acloudguru.com\">https://acloudguru.com</a> Kurzy zamerané hlavne na cloudové technológie (AWS, GCP, Azure), Linux, DevOps a pár ďalších okruhov. Súčasťou sú tzv. laby v účte na študijné účely, kde si môžete prakticky vyskúšať úlohy</p>\n<p><a href=\"https://checkmarx.com/try-codebashing\">https://checkmarx.com/try-codebashing</a> Školenie aplikačnej bezpečnosti, interaktívne lekcie pekne vysvetlia jednotlivé typy zraniteľností, ako prebiehajú ich zneužitia a útoky a ako im predísť</p>\n<p><a href=\"https://www.oreilly.com\">https://www.oreilly.com</a> Vydavateľstvo odbornej literatúry známe knihami s ohrozenými živočíšnymi druhmi na obálke, poskytuje tiež prístup k videám, interaktívnym kurzom a školeniam naživo</p>\n<p><a href=\"https://junior.guru\">https://junior.guru</a> Výborne spracovaný český web pre záujemcov o IT, v príručke rozoberá, čo si predstaviť pod programovaním, čo naňho potrebujete, ako sa učiť, ako zohnať prvú prácu aj ako sa posunúť od juniora ďalej</p>\n<p><a href=\"https://modernafirma.podbean.com\">https://modernafirma.podbean.com</a> Podcast Grishiho zo štúdia Wezeo a web inštruktora Yablka na témy v 3 oblastiach: premena na modernú firmu, budovanie digitálneho produktu, skúsenosti úspešných lídrov</p>\n<p><a href=\"https://www.glassdoor.com\">https://www.glassdoor.com</a> Anonymné recenzie firiem, informácie o platoch, hodnotenia pohovorov a otázky z nich</p>\n<p><a href=\"https://www.levels.fyi\">https://www.levels.fyi</a> Informácie o platoch v top firmách v IT odvetví</p>\n<p><a href=\"https://www.cwjobs.co.uk/salary-checker/salary-calculator\">https://www.cwjobs.co.uk/salary-checker/salary-calculator</a> Štatistiky o platoch v IT odvetví v UK</p>\n<p>Bonusový tip: veľa užitočného sa dozvedám prostredníctvom LinkedInu. Sledujte hashtagy, ktoré Vás zaujímajú, zapojte sa do skupín, nájdite si ľudí, ktorí tvoria dobrý obsah. Za mňa napr.:<br>\n<a href=\"https://sk.linkedin.com/in/zdenkovrabel\">Zdenko Vrabel</a> - infrastructure engineer, píše o kóde, cloude a (samozrejme) infraštruktúre<br>\n<a href=\"https://sk.linkedin.com/in/jbednar\">Juraj Bednár</a> - etický hacker, autor kurzov a kníh, venuje sa najmä slobode, kryptomenám, biohackingu a lepšiemu životu<br>\n<a href=\"https://sk.linkedin.com/in/filip-hric-11a5b1126\">Filip Hric</a> - ambasádor Cypress (testovacieho frameworku pre weby) na Slovensku a autor kurzov</p>\n",
      "date_published": "2022-04-04T00:00:00-00:00"
    },{
      "id": "https://monikajassova.github.io/posts/moja-cesta/",
      "url": "https://monikajassova.github.io/posts/moja-cesta/",
      "title": "Moja cesta do sveta IT",
      "content_html": "<p><em>V prvom príspevku svojho blogu začínam zľahka a osobnejšie</em></p>\n<p>Pracujem ako softvérový tester a tento vzrušujúci a pestrý svet milujem. Do IT som sa však dostala okľukou. Keď som si na strednej v Turbo Pascale naprogramovala &quot;Matrix&quot; (rozumej vypisovanie náhodných reťazcov v zelenej farbe na čiernom pozadí), cítila som sa ako majster sveta 😄. Pre zaujímavosť, zhruba v tom čase vznikol YouTube a prvé videá sme pozerali práve na hodine informatiky. Keď prišlo na rozhodovanie čo po gymnáziu, zvažovala som aj informatiku, no pred elektrotechnikou a fyzikou som mala priveľký rešpekt. V mojom okolí sa nenašiel nikto, kto by tento smer schvaľoval a navrhol aspoň to skúsiť. Vybrala som si teda bežnejšiu a istejšiu cestu a išla na ekonómiu.</p>\n<p>Po vysokej škole som sa zamestnala ako účtovníčka a keď sa vrátila pani, ktorú som zastupovala počas materskej dovolenky, musela som sa porúčať. Dlho sa mi nedarilo nájsť nové zamestnanie, dokonca ani magentové Téčko, kam vraj berú každého, kto ovláda angličtinu, ma nikdy nepozvalo na pohovor. Až mi raz Facebook ukázal príspevok spolužiaka, že IT firma, v ktorej pracuje, otvára v spolupráci s SOŠ trojročné nadstavbové štúdium s garantovaným pracovným miestom pre absolventov. Tak som si povedala, že kedy, keď nie teraz a prihlásila sa.</p>\n<p>Zasadla som opäť do školských lavíc, v 28 rokoch ako najstaršia v ročníku a ako jediná žena. Čakal ma rok a pol denného štúdia a potom prax vo firme (po 3mes. skúšobnej dobe zmluva na TPP), všetko som zvládla bez problému a úspešne štúdium dokončila.<br>\nVo firme som bola pridelená na projekty, kde sa manuálne testovali webstránky, mobilné a desktopové aplikácie. Ja som však chcela kódiť a keď tá možnosť neprichádzala, zmenila som zamestnávateľa.</p>\n<p>V novej firme som sa dostala do čerstvo sformovaného big data tímu, kde som mala zastrešiť automatizovaný testing. Bola som sám tester v tíme, o doméne big data som nevedela nič a programovací jazyk Scala bol pre mňa tiež nový. Kolegovia developeri boli na tom podobne a nikto iný vo firme sa big data nevenoval, takže nebolo s kým konzultovať. Začiatky teda boli ťažké, ale chytila som sa, big data sa mi zapáčili a veľa som sa naučila. Posledný rok môjho pôsobenia vo firme som dostávala developerské úlohy, keďže som si chcela skúsiť aj rolu developera.</p>\n<p>Počas korony prišla ponuka z domény blockchainu, ktorá ma osobne zaujíma a rozhodla som sa ju prijať. Znamenala hneď niekoľko zmien naraz: prácu na kontrakt, pre zahraničnú firmu s vlastným produktom, 100% remote a vo sfére open source. Verím, že sa tu opäť veľa naučím a posuniem odborne 🙂.</p>\n<p><img src=\"/img/journey.jpg\" alt=\"Cesta\"></p>\n<h3 id=\"moje-postrehy-a-odpor%C3%BA%C4%8Dania\">Moje postrehy a odporúčania <a class=\"direct-link\" href=\"#moje-postrehy-a-odpor%C3%BA%C4%8Dania\">#</a></h3>\n<p><em>Nasledujú subjektívne názory vychádzajúce z osobných skúseností a hlavne z pohľadu testovania a vývoja</em></p>\n<ul>\n<li>výhodou IT je, že šancu uplatniť sa máte aj v neskoršom veku. Stačí mať predpoklady (logické myslenie), chuť veľa sa učiť a vedieť po anglicky (aspoň tak, aby ste rozumeli študijným materiálom a dokumentácii). Hodí sa aj záujem o to, ako veci fungujú.</li>\n<li>ak ovládate angličtinu na komunikatívnej úrovni, otvárajú sa Vám formou práce z domu možnosti prakticky po celom svete. IT firmy majú nedostatok ľudí, často stačí, ak máte motiváciu, chýbajúce znalosti získate za pochodu. Aj keď samozrejme záleží na firme, 2 moje pohovory skončili hodnotením, že viac chcem ako viem a raz to znamenalo stopku, druhý raz postup do ďalšieho kola.</li>\n<li>IT je špecifické tým, že na prácu v ňom nepotrebujete formálne vzdelanie a študijné materiály, tutoriály nájdete voľne dostupné na internete. Existujú tiež online kurzy, prezenčná výučba, firmy majú tzv. farmy/akadémie, kde si vychovávajú ľudí, prípadne si môžete nájsť mentora. Záleží len na štýle učenia, ktorý Vám najviac vyhovuje a koľko času ste ochotní štúdiu venovať. Čítala som dokonca o panej, čo za 2 dni prešla kurz na automatizovaný testing v Seleniu, na štvrtý deň išla na pohovor a vzali ju.</li>\n<li>nemusíte hneď ovládať zložité koncepty, zložitejšie veci sa naučíte vtedy, keď ich budete potrebovať. Väčšina projektov nie je raketová veda, ale ničím výnimočné webové alebo mobilné aplikácie. V programovaní sa dá cvičením zlepšiť a rozvíjať potrebné myslenie (learning by doing - učenie sa robením). IT je rozsiahle, ľudia sa špecializujú (je lepšie poznať vybranú oblasť do hĺbky ako vedieť z každého rožku trošku). Ale je super, ak máte poznatky aj z príbuzných oblastí a všeobecný IT prehľad.</li>\n<li>je fajn, ak máte skúsenejších kolegov/mentorov, ktorí Vám poradia a potiahnu Vás. Podľa môjho názoru sa sami viete dostať len po určitú úroveň a metódou pokus-omyl sa síce poučíte, ale stojí to veľa času a úsilia.</li>\n<li>práca v IT (technická) je vlastne nikdy nekončiace sa štúdium. Neustále prichádzajú nové požiadavky, nové technológie, existujúce technológie sa vyvíjajú a zastarávajú.</li>\n<li>v IT je celá škála profesií, nie všetky sú technické. Okrem developera, testera, DevOps, architekta, databázového administrátora, systémového administrátora sa môžete uplatniť na manažérskych pozíciách (produktový, projektový manažér atď.), ako scrum master, product owner, technical writer (dokumentarista), biznis analytik, UI/UX dizajnér...</li>\n<li>je relatívne ľahké zmeniť svoje smerovanie, viete sa v rámci kariérnych ciest posúvať vertikálne aj horizontálne a prechádzať medzi vyššie spomenutými pozíciami</li>\n<li>práca je rôznorodá, projekt sa týka nejakej domény reálneho alebo virtuálneho sveta. Napr. pri SW na vyhotovovanie reportov z glukomeru potrebujete vedieť aj niečo o cukrovke, pri dátach z platformy pre online reklamy sa dozviete čo-to o digitálnom marketingu.</li>\n<li>vývoj SW nie je len o osamelom ťukaní do počítača, zahŕňa aj plánovanie práce, diskusie s kolegami týkajúce sa riešenia úloh, s ostatnými spolupracujúcimi profesiami, so zákazníkom a pod., takže je dôležitá komunikácia</li>\n<li>nie je sranda celé dni sedieť za počítačom (z fyzického ani psychického hľadiska), oplatí sa dbať na ergonómiu, psychohygienu a kompenzovať sedenie pohybom a cvičením, zdravie máme len jedno</li>\n<li>na záver na odľahčenie: nie všetci v IT sú kocky v nemoderných outfitoch a ponožkami v sandáloch 😄. Nájde sa pár takých, ináč sú tu normálni ľudia ako všade inde, introverti aj extroverti, veriaci aj neveriaci, metalisti, hiphoperi, športovci, umelecky založení, manuálne zruční... A že sa ajťáci nevedia baviť so ženami alebo nemajú partnerky je tiež len mýtus.</li>\n</ul>\n",
      "date_published": "2022-02-02T00:00:00-00:00"
    }
  ]
}
